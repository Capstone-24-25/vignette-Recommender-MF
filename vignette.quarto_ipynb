{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Recommendor Systems with Deep Learning - Matrix Factorization\"\n",
        "author: \"Kuan-I Lu, Colin Nguyen, Candis Wu, Caitlyn Vasquez, Carter Kulm\"\n",
        "date: \"`r Sys.Date()`\"\n",
        "format: html\n",
        "---\n",
        "\n",
        "\n",
        "# Overview\n",
        "Our vignette is on reccomender systems that utilize deep learning techniques.  Reccomendation systems are a tool that allow us to analyze interactions between users and items, leveraging historical data to predict future interactions.  There are two types of reccomendations systems, content-based and colloboaring filtering, which is what are using.  In collaborative filtering, the system predicts user preferences based off the behavior of oother users, assuming that users with similar past preferences will have similar future preferences.  Furthermore, advanced reccomendation systems can incorperate machine learning and deep learning techniques to improve accuracy, allowing the system to capture complex on linear relationships in the data.\n",
        "\n",
        "# Data Description\n",
        "\n",
        "This dataset is sourced from Kaggle after searching for data that matched the structure of examples referenced in the Dive Into Deep Learning textbook. The dataset contains user ratings for products, making it a strong candidate for testing recommendation systems, particularly collaborative filtering models.\n",
        "\n",
        "The dataset is part of the Amazon Reviews Data repository, which was curated by Julian McAuley. It contains product reviews and ratings across multiple categories. For our project, we specifically utilized the Electronics dataset. The original data source can be found [here](https://www.kaggle.com/datasets/saurav9786/amazon-product-reviews).\n",
        "\n",
        "Note: In our data folder we will only include 5000 rows of data for reference because the entire data file is too large to be uploaded on github. \n",
        "\n",
        "\n",
        "### Attribute information: \\\n",
        "-   `userId` : Every user identified with a unique id (First Column)\\\n",
        "-   `productId` : Every product identified with a unique id (Second Column)\\\n",
        "-   `Rating` : Rating of the corresponding product by the corresponding user (Third Column)\\\n",
        "-   `timestamp` : Time of the rating (Fourth Column)\\\n",
        "\n",
        "# Matrix Factorization\n",
        "\n",
        "\n",
        "\n",
        "# Baseline Model(SVD)\n",
        "\n",
        "Singular value decomposition (or SVD) is a method of matrix factorization that consists of rescaling and multiple rotations that eventually results in three components: U, a unitary matrix consisting of left singular vectors, ∑, a rectangular matrix consisting of eigenvectors on the diagonal, and V, a complex unitary matrix with right singular vectors. To implement SVD in Python we will use the functions drawn from the scikit-surprise package. We will first specify a reader() object which will help to parse our input data.\n"
      ],
      "id": "609bff10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from surprise import SVD, Dataset, Reader, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(data[['user_id', 'item_id', 'rating']], reader)"
      ],
      "id": "dd07c18a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then create our training and testing sets in addition to initializing our svd model. \n",
        "\n",
        "```{python} eval=False\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "svd = SVD()\n",
        "```\n",
        "\n",
        "Next, we compute predictions and analyze the model’s accuracy using RMSE and MAE as our evaluation metrics. \n"
      ],
      "id": "5fa6622d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions = svd.test(testset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "mae = accuracy.mae(predictions)"
      ],
      "id": "840aabc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RMSE: 1.2943\n",
        "MAE: 1.0190\n",
        "\n",
        "Thus we see that our baseline model, SVD, didn't perform horribly in terms of RMSE and MAE. \n",
        "\n",
        "# Deep Learning"
      ],
      "id": "6cd35f1c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/envs/dsenv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}