---
title: "Recommendor Systems with Deep Learning - Matrix Factorization"
author: "Kuan-I Lu, Colin Nguyen, Candis Wu, Caitlyn Vasquez, Carter Kulm"
date: "`r Sys.Date()`"
format: html
---

# Overview

Our vignette is on recommender systems that utilize deep learning techniques. Recommendation systems are a tool that allow us to analyze interactions between users and items, leveraging historical data to predict future interactions. There are two types of recommendation systems, content-based and collaborative filtering, which is what we are using. In collaborative filtering, the system predicts user preferences based on the behavior of other users, assuming that users with similar past preferences will have similar future preferences. Furthermore, advanced recommendation systems can incorporate machine learning and deep learning techniques to improve accuracy, allowing the system to capture complex linear relationships in the data.

# Data Description

This dataset is sourced from Kaggle after searching for data that matched the structure of examples referenced in the Dive Into Deep Learning textbook. The dataset contains user ratings for products, making it a strong candidate for testing recommendation systems, particularly collaborative filtering models.

The dataset is part of the Amazon Reviews Data repository, which was curated by Julian McAuley. It contains product reviews and ratings across multiple categories. For our project, we specifically utilized the Electronics dataset. The original data source can be found [here](https://www.kaggle.com/datasets/saurav9786/amazon-product-reviews).

Note: In our data folder we will only include 5000 rows of data for reference because the entire data file is too large to be uploaded on github. Note: In our data folder we will only include 5000 rows of data for reference because the entire data file is too large to be uploaded on github.

### Attribute information: 

-   `userId` : Every user identified with a unique id (First Column)\
-   `productId` : Every product identified with a unique id (Second Column)\
-   `Rating` : Rating of the corresponding product by the corresponding user (Third Column)\
-   `timestamp` : Time of the rating (Fourth Column)\

### Exploratory Data Analysis
![Figure 1. Bar Graph of Numbers of Ratings vs Ratings](img/EDA Rating distribution.png)
This bar chart illustrates the distribution of numerical ratings across various rating scores. The x-axis represents the ratings, ranging from 0.5 to 5.0 in 0.5 increments, while the y-axis shows the number of ratings, scaled in millions. The highest count of ratings is associated with a rating of 5.0, exceeding 4 million ratings. Other ratings, such as 1.0, 3.0, and 4.0, have significantly fewer ratings in comparison.

![Figure 2. Distribution of Number of Ratings per User](img/EDA Rating per user distribution.png)

This bar chart represents how frequently users provide a specific number of ratings. The x-axis denotes the number of ratings given by users, ranging from 0 to 50, and the y-axis shows the count of users, scaled in millions. A vast majority of users provide very few ratings, with the highest concentration around 1 to 2 ratings per user. The frequency of users rapidly decreases as the number of ratings per user increases.


# Matrix Factorization

![Figure 3. Illustration of matrix factorization model](img/MF-illustration.png)

There are several methods to approach this, one being simply applying Singular Value Decomposition (SVD) and obtaining the user and item matrix directly. This is going to be our benchmark. A more advanced approach is to implement deep learning algorithms to train for the weights (parameters) in the user and item matrix, respectively. To make the product of these two matrices having values close to the observed matrix.

# Baseline Model (SVD)

![Figure 4. Illustration of SVD](img/svd.png)

Singular value decomposition (or SVD) is a method of matrix factorization that consists of rescaling and multiple rotations that eventually results in three components: U, a unitary matrix consisting of left singular vectors, ∑, a rectangular matrix consisting of eigenvectors on the diagonal, and V, a complex unitary matrix with right singular vectors. To implement SVD in Python we will use the functions drawn from the scikit-surprise package. We will first specify a reader() object which will help to parse our input data.

``` python
from surprise import SVD, Dataset, Reader, accuracy
from surprise.model_selection import train_test_split
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(data[['user_id', 'item_id', 'rating']], reader)
```

We then create our training and testing sets in addition to initializing our svd model. We then create our training and testing sets in addition to initializing our svd model.

``` python
trainset, testset = train_test_split(data, test_size=0.2)
svd = SVD()
```

Next, we compute predictions and analyze the model’s accuracy using RMSE and MAE as our evaluation metrics. Next, we compute predictions and analyze the model’s accuracy using RMSE and MAE as our evaluation metrics.

``` python
predictions = svd.test(testset)
rmse = accuracy.rmse(predictions)
mae = accuracy.mae(predictions)
```

RMSE: 1.2943 MAE: 1.0190

Thus we see that our baseline model, SVD, didn't perform horribly in terms of RMSE and MAE. Thus we see that our baseline model, SVD, performed pretty well in terms of RMSE and MAE.

# Deep Learning

# Advanced Deep Learning Method

We can see that the We can see that the simple deep learning framework
